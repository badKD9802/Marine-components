from contextlib import asynccontextmanager
from fastapi import FastAPI
from decouple import config
from pydantic import BaseModel, Field
from fastapi.middleware.cors import CORSMiddleware
import google.genai as genai
from google.genai import types
import os
from dotenv import load_dotenv
import json

load_dotenv()

import asyncio

from db import init_db, close_db, init_vector_db, close_vector_db, get_all_products, get_product_by_id, create_product, get_products_for_ai_prompt
from admin import router as admin_router
from rag_chat import router as rag_chat_router, cleanup_old_conversations
from mail_compose import router as mail_compose_router, gmail_auto_check_loop
from inquiry import router as inquiry_router
from rag import search_similar_chunks

_scheduler_task = None


# Lifespan: DB init/close + Gmail ìë™ ì²´í¬ ìŠ¤ì¼€ì¤„ëŸ¬
@asynccontextmanager
async def lifespan(app):
    global _scheduler_task
    await init_db()
    await init_vector_db()
    await cleanup_old_conversations()
    _scheduler_task = asyncio.create_task(gmail_auto_check_loop())
    yield
    if _scheduler_task:
        _scheduler_task.cancel()
        try:
            await _scheduler_task
        except asyncio.CancelledError:
            pass
    await close_vector_db()
    await close_db()


# 1. ì•± ìƒì„±
print("app ìƒì„± ì¤‘...")
app = FastAPI(lifespan=lifespan)
print("=== í™˜ê²½ë³€ìˆ˜ í™•ì¸ ===")
print(f"  GOOGLE_API_KEY: {'ì„¤ì •ë¨ (' + os.environ['GOOGLE_API_KEY'][:8] + '...)' if os.environ.get('GOOGLE_API_KEY') else 'ë¯¸ì„¤ì •'}")
print(f"  OPENAI_API_KEY: {'ì„¤ì •ë¨ (' + os.environ['OPENAI_API_KEY'][:8] + '...)' if os.environ.get('OPENAI_API_KEY') else 'ë¯¸ì„¤ì •'}")
print(f"  ADMIN_PASSWORD: {'ì„¤ì •ë¨ (' + str(len(os.environ.get('ADMIN_PASSWORD',''))) + 'ì)' if os.environ.get('ADMIN_PASSWORD') else 'ë¯¸ì„¤ì •'}")
print(f"  DATABASE_URL:   {'ì„¤ì •ë¨' if os.environ.get('DATABASE_URL') else 'ë¯¸ì„¤ì •'}")
print(f"  PGVECTOR_DB:    {'ì„¤ì •ë¨' if os.environ.get('PGVECTOR_DATABASE_URL') else 'ë¯¸ì„¤ì •'}")
print("====================")


# 2. CORS ì„¤ì •
print("app ìƒì„± ì¤‘...2")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
app.include_router(admin_router)
app.include_router(rag_chat_router)
app.include_router(mail_compose_router)
app.include_router(inquiry_router)
print("app ìƒì„±ì™„ë£Œ")


# 3. ë°ì´í„° í˜•ì‹ ì •ì˜
class ChatRequest(BaseModel):
    message: str
    history: list[dict] = []


class ProductCreate(BaseModel):
    image: str
    part_no: str
    price: str
    brand: str = ""
    category: str = ""
    name: dict
    description: dict
    category_name: dict = {}
    detail_info: dict = {}
    specs: dict = {}
    compatibility: dict = {}


### AI ëª¨ë¸ ë‹µë³€ ìƒì„± í•¨ìˆ˜ ###
def model_answer(api_key, model_name, system_prompt, history, user_message):
    class MarineTechResponse(BaseModel):
        reply: str = Field(description="ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ì˜ë§ˆë¦°í…Œí¬ ìƒë‹´ì›ì˜ ë©”ì¸ ë‹µë³€")
        suggested_questions: list[str] = Field(description="ì‚¬ìš©ìê°€ ì´ì–´ì„œ ë¬¼ì–´ë³¼ ë§Œí•œ ì¶”ì²œ ì§ˆë¬¸ 1~3ê°œ (ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´)")


    print("ëª¨ë¸ì— í”„ë¡¬í”„íŠ¸ ì „ë‹¬ ì¤‘...")
    client = genai.Client(api_key=api_key)

    contents = []
    for turn in history:
        # history í˜•ì‹ì´ í˜¸í™˜ë˜ë„ë¡ ì¡°ì • (í•„ìš” ì‹œ)
        contents.append({"role": turn["role"], "parts": [{"text": turn["parts"]}]})
    contents.append({"role": "user", "parts": [{"text": user_message}]})

    print(f"ëŒ€í™” ë‚´ìš© ì „ë‹¬ ì¤‘: {contents}")

    # 2. GenerateContentConfigì— response_mime_typeê³¼ response_schemaë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    response = client.models.generate_content(
        model=model_name,
        contents=contents,
        config=types.GenerateContentConfig(
            system_instruction=system_prompt,
            temperature=0.7,
            # [í•µì‹¬ ë³€ê²½ ì‚¬í•­] JSON ì¶œë ¥ì„ ê°•ì œí•©ë‹ˆë‹¤.
            response_mime_type="application/json", 
            response_schema=MarineTechResponse 
        )
    )

    print(f"ë‹µë³€ ìƒì„± ì™„ë£Œ")

    return response.text

# --- [AI ë¡œì§] ---
async def get_ai_response(user_message: str, history: list[dict]):
    user_message = user_message.strip()

    api_key = config("GOOGLE_API_KEY")

    if api_key:
        print(f"API Key ë¡œë“œ ì„±ê³µ", flush=True)

        model_name = 'gemini-2.5-flash'

        # DBì—ì„œ ì œí’ˆ ì •ë³´ ë™ì  ë¡œë”©
        product_info = await get_products_for_ai_prompt()
        if not product_info:
            product_info = """- ì–€ë§ˆ ì»¤ë„¥íŒ… ë¡œë“œ ë² ì–´ë§: 2,000ì›
- ë§ˆë¦° ë””ì ¤ ì—”ì§„ í”Œë¦°ì € ë² ëŸ´: 400,000ì›
- ì„ ë°• ì—”ì§„ ì˜ˆë¹„ ë¶€í’ˆ ëª¨ìŒ: ë¬¸ì˜ ë°”ëŒ
- í”¼ìŠ¤í†¤ í•€ ë¶€ì‹œ: 100,000ì›
- ë‹¤ì´í•˜ì¸  ë°¸ë¸Œ ìŠ¤í…œ ì”°: 2,600ì›"""

        # RAG: ì—…ë¡œë“œëœ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì²­í¬ ê²€ìƒ‰
        rag_context = ""
        try:
            rag_chunks = await search_similar_chunks(user_message, top_k=5, purpose="consultant")
            if rag_chunks:
                rag_lines = []
                for chunk in rag_chunks:
                    if chunk["similarity"] > 0.3:
                        rag_lines.append(f"[{chunk['filename']}] {chunk['chunk_text']}")
                if rag_lines:
                    rag_context = "\n\n## ì°¸ê³  ë¬¸ì„œ (ì—…ë¡œë“œëœ ê¸°ìˆ  ìë£Œ)\n" + "\n---\n".join(rag_lines) + "\nìœ„ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ë˜, ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”."
        except Exception as e:
            print(f"RAG ê²€ìƒ‰ ì˜¤ë¥˜ (ë¬´ì‹œ): {e}", flush=True)

        system_prompt = f"""
        ë‹¹ì‹ ì€ ì˜ë§ˆë¦°í…Œí¬ì˜ AI ìƒë‹´ì›ì…ë‹ˆë‹¤.
        ì˜ë§ˆë¦°í…Œí¬ëŠ” ì„ ë°• ì—”ì§„ ë° ë¶€í’ˆì„ íŒë§¤í•˜ëŠ” íšŒì‚¬ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì˜ë§ˆë¦°í…Œí¬ì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
        ì‘ë‹µì€ ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤. ì‘ë‹µ JSONì€ 'reply' (ë©”ì¸ ë‹µë³€)ì™€ 'suggested_questions' (ë‹¤ìŒ ì§ˆë¬¸ ì œì•ˆ 1~3ê°œ) ë‘ ê°œì˜ í‚¤ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
        'suggested_questions'ëŠ” ë°°ì—´ì´ì–´ì•¼ í•˜ë©°, ì œì•ˆí•  ì§ˆë¬¸ì´ ì—†ëŠ” ê²½ìš° ë¹ˆ ë°°ì—´ë¡œ ë‘ì„¸ìš”.

        ## ì˜ë§ˆë¦°í…Œí¬ ì •ë³´
        ì˜ë§ˆë¦°í…Œí¬ì—ì„œ íŒë§¤í•˜ëŠ” ì œí’ˆë“¤ì˜ ê°€ê²© ì„¤ëª…ì…ë‹ˆë‹¤:
{product_info}
        ìì„¸í•œ ë‚´ìš©ì€ ì¶”ì²œ ë¶€í’ˆ ëª©ë¡ì„ ì°¸ê³ í•˜ì„¸ìš”.

        ì˜ë§ˆë¦°í…Œí¬ëŠ” 20ë…„ ì´ìƒì˜ ì „ë¬¸ ê²½í—˜ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, YANMAR, Daihatsu ë“± ê¸€ë¡œë²Œ ë¸Œëœë“œì˜ ì •í’ˆ ë¶€í’ˆë§Œì„ ì·¨ê¸‰í•©ë‹ˆë‹¤.
        ì‹ ì† ë°°ì†¡ê³¼ 24/7 ê¸°ìˆ  ì§€ì›ì„ ì œê³µí•˜ë©°, 100% ì •í’ˆ ë³´ì¦ê³¼ ê¸€ë¡œë²Œ ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•´ ì•ˆì •ì ì¸ ì¬ê³ ë¥¼ í™•ë³´í•©ë‹ˆë‹¤.
        ì „ë¬¸ ì»¨ì„¤íŒ…, ì¬ê³  ê´€ë¦¬, ë§ì¶¤ ê²¬ì  ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
{rag_context}

        ## ì˜ˆì‹œ
        ì‚¬ìš©ì: ì–€ë§ˆ ì»¤ë„¥íŒ… ë¡œë“œ ë² ì–´ë§ ê°€ê²©ì´ ì–¼ë§ˆì¸ê°€ìš”?
        AI: {{
            "reply": "ì–€ë§ˆ ì»¤ë„¥íŒ… ë¡œë“œ ë² ì–´ë§ì€ 2,000ì›ì…ë‹ˆë‹¤.",
            "suggested_questions": ["ë‹¤ë¥¸ ë² ì–´ë§ë„ ìˆë‚˜ìš”?", "ë°°ì†¡ì€ ì–¼ë§ˆë‚˜ ê±¸ë¦¬ë‚˜ìš”?", "ê²¬ì  ìš”ì²­ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?"]
        }}

        ì‚¬ìš©ì: ì•ˆë…•í•˜ì„¸ìš”
        AI: {{
            "reply": "ì•ˆë…•í•˜ì„¸ìš”! ì˜ë§ˆë¦°í…Œí¬ AI ìƒë‹´ì›ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?",
            "suggested_questions": ["íšŒì‚¬ ì†Œê°œ", "ì œí’ˆ ëª©ë¡ ë³´ê¸°", "ê²¬ì  ë¬¸ì˜"]
        }}
        """

        try:
            response_text = model_answer(api_key, model_name, system_prompt, history, user_message)
        except Exception as e:
            print(f"Gemini API í˜¸ì¶œ ì˜¤ë¥˜: {e}", flush=True)
            return {"reply": "ì£„ì†¡í•©ë‹ˆë‹¤. AI ì„œë²„ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", "suggested_questions": []}

        try:
            gemini_response = json.loads(response_text)
            reply = gemini_response.get("reply", "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            suggested_questions = gemini_response.get("suggested_questions", [])
            return {"reply": reply, "suggested_questions": suggested_questions}
        except json.JSONDecodeError:
            print(f"Gemini ì‘ë‹µ JSON íŒŒì‹± ì˜¤ë¥˜: {response_text}")
            return {"reply": "ì£„ì†¡í•©ë‹ˆë‹¤. ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", "suggested_questions": []}

    else:
        print("API Keyë¥¼ í™˜ê²½ë³€ìˆ˜ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.", flush=True)
        return {"reply": "API Keyë¥¼ í™˜ê²½ë³€ìˆ˜ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤", "suggested_questions": []}

# -------------------------------------------

# 4. API ì—”ë“œí¬ì¸íŠ¸
@app.post("/chat")
async def chat(request: ChatRequest):
    print(f"ìœ ì € ì§ˆë¬¸: {request.message}")
    print(f"ì±„íŒ… ê¸°ë¡: {request.history}")

    response = await get_ai_response(request.message, request.history)
    print(f"AI ë‹µë³€: {response['reply']}")
    print(f"ì œì•ˆëœ ì§ˆë¬¸: {response['suggested_questions']}")

    return response


# í¬íŠ¸í´ë¦¬ì˜¤ ì±—ë´‡ ì „ìš© ì—”ë“œí¬ì¸íŠ¸
@app.post("/portfolio-chat")
async def portfolio_chat(request: ChatRequest):
    """ë°°ê²½ë“ ì§€ì›ì í¬íŠ¸í´ë¦¬ì˜¤ ì „ìš© AI ì±—ë´‡"""
    print(f"[í¬íŠ¸í´ë¦¬ì˜¤] ìœ ì € ì§ˆë¬¸: {request.message}")

    api_key = config("GOOGLE_API_KEY")
    if not api_key:
        return {"reply": "API Keyë¥¼ í™˜ê²½ë³€ìˆ˜ì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤", "suggested_questions": []}

    # í¬íŠ¸í´ë¦¬ì˜¤ ì „ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    portfolio_content = """
## ë°°ê²½ë“ (AI Engineer) í”„ë¡œí•„

### ê¸°ë³¸ ì •ë³´
- ì´ë¦„: ë°°ê²½ë“
- ì§ë¬´: AI Engineer | RAG & AI Agent Specialist
- ì´ë©”ì¼: qorudemr00@naver.com
- ì „í™”: 010-4056-2656
- ìœ„ì¹˜: ë¶€ì‚°ê´‘ì—­ì‹œ ë‚¨êµ¬
- GitHub: github.com/badKD9802
- í™ˆí˜ì´ì§€: badkd9802.github.io/Marine-components/docs/

### í•µì‹¬ ì—­ëŸ‰
"RAG ê²€ìƒ‰ í’ˆì§ˆì„ ì„¤ê³„í•˜ê³ , ì‹¤ë¬´í˜• AI Agentë¥¼ êµ¬ì¶•í•˜ëŠ” AI ì—”ì§€ë‹ˆì–´"

**ì£¼ìš” ì„±ê³¼:**
- RAG ë‹µë³€ ì •í™•ë„: 92%
- ê²€ìƒ‰ Hitrate@5: 91%
- í• ë£¨ì‹œë„¤ì´ì…˜ í†µê³¼ìœ¨: 91%
- G-EVAL í’ˆì§ˆ í‰ê°€: 4.3/5.0

### ì£¼ìš” í”„ë¡œì íŠ¸

#### 1. í•œêµ­ìì‚°ê´€ë¦¬ê³µì‚¬(KAMCO) ê·¸ë£¹ì›¨ì–´ ì¬êµ¬ì¶• ì‚¬ì—… - AI ë„ì… (2024.10 ~ 2026.01)
**ì—­í• :** ì• ìì¼ì†Œë‹¤ ì„ ì„ì—°êµ¬ì› | ê¸°ì—¬ë„ 30%
**ê¸°ìˆ  ìŠ¤íƒ:** Python, LangGraph, vLLM, Milvus DB, Oracle/MariaDB, H100/H200 GPU

**í•µì‹¬ ì„±ê³¼:**
1. **ëŒ€ê·œëª¨ ë¬¸ì„œ ê¸°ë°˜ RAG ì‹œìŠ¤í…œ êµ¬ì¶•**
   - 1,000ë§Œê±´ ê·œëª¨ì˜ ë‚´ë¶€ ë¬¸ì„œ ì²˜ë¦¬
   - Context-Aware RAG Pipeline: OCRì—ì„œ ê²€ìƒ‰ê¹Œì§€ ì „ ê³¼ì • ì„¤ê³„
   - ë©”íƒ€ë°ì´í„° í™œìš©ìœ¼ë¡œ ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒ
   - Chunk ì»¨í…ìŠ¤íŠ¸ ë³´ê°•: LLMìœ¼ë¡œ 'ìš”ì•½'ê³¼ 'ì˜ˆìƒ ì§ˆë¬¸' ìƒì„±
   - í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + Reranking: Sparse(í‚¤ì›Œë“œ) + Dense(ì˜ë¯¸) ê²°í•©
   - ì²­í¬ ê²€ì¦ ë¡œì§ìœ¼ë¡œ ë‹µë³€ ê°€ëŠ¥ ì—¬ë¶€ ê²€ì¦
   - **ì„±ê³¼:** ë‹µë³€ ì •í™•ë„ 92%, Hitrate@5 91%, í• ë£¨ì‹œë„¤ì´ì…˜ í†µê³¼ìœ¨ 91%

2. **LangGraph ê¸°ë°˜ ì—…ë¬´ ìë™í™” AI Agent**
   - ìì—°ì–´ ìš”ì²­ â†’ ì˜ë„ íŒŒì•… â†’ API ì‹¤í–‰ â†’ ê²°ê³¼ ì‘ë‹µì˜ End-to-End íŒŒì´í”„ë¼ì¸
   - 5ì¢… API ì—°ë™: íšŒì˜ì‹¤ ì˜ˆì•½, ì¼ì • ê´€ë¦¬, ì„ì› ì¼ì • ì¡°íšŒ, ê²°ì¬ ì–‘ì‹ í˜¸ì¶œ ë“±
   - íŒŒë¼ë¯¸í„° ëˆ„ë½ ì‹œ ì—­ì§ˆë¬¸(Slot Filling), API ì‹¤íŒ¨ ì‹œ ì›ì¸ ì•ˆë‚´
   - ì‚¬ìš©ì í‰ê°€: "ë¶ˆí¸í•¨ ì—†ê³  ë§¤ë„ëŸ½ë‹¤"

3. **ë¬¸ì„œ ìš”ì•½ Â· ë²ˆì—­ Â· ì´ˆì•ˆ ì‘ì„± ì„œë¹„ìŠ¤**
   - ë¬¸ì„œ ìœ í˜•ë³„ í”„ë¡¬í”„íŠ¸: ë³´ê³ ì„œ, ì´ë©”ì¼, ê·œì • ë“± ì „ìš© í…œí”Œë¦¿ ê°œë°œ
   - ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì†ë„ 2ë°° ê°œì„  (5í˜ì´ì§€ 17.5ì´ˆ â†’ 9í˜ì´ì§€ 12.3ì´ˆ)
   - ë‹¤êµ­ì–´ ì§€ì›: ì¼ë³¸ì–´, ì˜ì–´ ë²ˆì—­ ë° íšŒì‹ ë¬¸/ë³´ê³ ì„œ ì´ˆì•ˆ ìƒì„±
   - G-EVAL í’ˆì§ˆ í‰ê°€: 4.3/5.0

**ìˆ˜ìƒ:**
- ğŸ† êµ­ë¬´ì´ë¦¬ìƒ ìˆ˜ìƒ - í•œêµ­ìì‚°ê´€ë¦¬ê³µì‚¬ ê·¸ë£¹ì›¨ì–´ ì¬êµ¬ì¶• ì‚¬ì—… AI ë„ì… ê¸°ì—¬
- ğŸ† 2025ë…„ ì„±ê³¼ê¸‰ ìˆ˜ë ¹

#### 2. AI ê¸°ë°˜ ì„ ë°• ë¶€í’ˆ ìƒë‹´ ì›¹ ì„œë¹„ìŠ¤ (ê°œì¸ í”„ë¡œì íŠ¸, ì§„í–‰ì¤‘)
- JavaScript, HTML, Gemini-2.5-Flash, RAG (ì˜ˆì •)
- ì„ ë°• ë¶€í’ˆ ê²€ìƒ‰ + AI ìƒë‹´ì‚¬ê°€ ìì—°ì–´ë¡œ ë¶€í’ˆ ì¶”ì²œ
- í–¥í›„ RAG êµ¬ì¡° + DB êµ¬ì¶• ê³„íš

#### 3. KMI ì§€ì •í•™ì  ì´ìŠˆ ì˜í–¥ ë¶„ì„ (2024.05 ~ 2024.07)
- í•œêµ­í•´ì–‘ìˆ˜ì‚°ê°œë°œì› ë¶ê·¹í•­ë¡œì§€ì›ë‹¨
- í•œêµ­-ë¶ìœ ëŸ½ í•­ë¡œì˜ ë¬¼ë™ëŸ‰/ìš´ì„/ìš´ì†¡ì¼ìˆ˜ ë°ì´í„° ìˆ˜ì§‘
- OLS íšŒê·€ë¶„ì„ìœ¼ë¡œ ì½”ë¡œë‚˜, ëŸ¬-ìš°ì „ìŸ, í™í•´ ì‚¬íƒœì˜ ì˜í–¥ ë¶„ì„
- Python, OLS íšŒê·€ë¶„ì„, ë°ì´í„° ì‹œê°í™”

#### 4. NLP ë…¼ë¬¸ - SMOTE ê¸°ë²• ì—°êµ¬ (2024.01 ~ 2024.07, ì„ì‚¬ ë…¼ë¬¸)
- ìŠ¤íŒ€ê²Œì„ë¦¬ë·° ë¶ˆê· í˜• í…ìŠ¤íŠ¸ ë¶„ë¥˜ ì„±ëŠ¥ í‰ê°€
- SMOTE/B-SMOTE/ADASYN 3ê°€ì§€ ê¸°ë²• ë¹„êµ ë° í´ë˜ìŠ¤ ë¹„ìœ¨ ìµœì í™” ì—°êµ¬
- NLP, SMOTE, ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ

#### 5. CIFAR-10 ì´ë¯¸ì§€ ë¶„ë¥˜ (2022.10 ~ 2022.11, 3íŒ€ ì¤‘ 1ë“±)
- PyTorchë¡œ VGG16/ResNet50/EfficientNet ê°œë°œ
- ì•™ìƒë¸” ê¸°ë²•ìœ¼ë¡œ ACC 0.8096 ë‹¬ì„± (1ë“±)
- 4ì¸ íŒ€ í”„ë¡œì íŠ¸

#### 6. IMDB í…ìŠ¤íŠ¸ ë¶„ë¥˜ ëª¨ë¸ (2022.10 ~ 2022.11)
- TensorFlowë¡œ RNN/LSTM/BiLSTM ëª¨ë¸ êµ¬í˜„
- ë‹¤ì¤‘ ë ˆì´ì–´ ì¡°í•©ìœ¼ë¡œ ìµœê³  ACC 0.8861 ë‹¬ì„±
- ê°œì¸ í”„ë¡œì íŠ¸

### ê¸°ìˆ  ìŠ¤íƒ

**AI / ML Framework:**
- LangGraph, LangChain, vLLM, OpenAI API, AsyncOpenAI
- PyTorch, TensorFlow

**Database:**
- Milvus DB, Oracle DB, MariaDB

**Language & Tools:**
- Python, JavaScript, HTML/CSS, Selenium

**Infrastructure:**
- H100 GPU (8ì¥), H200 GPU (8ì¥), gpt-oss-120b

### ê²½ë ¥ ë° í•™ë ¥

**ì• ìì¼ì†Œë‹¤ (2024.10 ~ í˜„ì¬)**
- ì„ ì„ì—°êµ¬ì›, DSíŒ€ (ì •ê·œì§)
- RAG ë° AI Agent ê°œë°œ ë‹´ë‹¹
- í•œêµ­ìì‚°ê´€ë¦¬ê³µì‚¬ ê·¸ë£¹ì›¨ì–´ AI ë„ì… í”„ë¡œì íŠ¸ ì£¼ë„

**í•œêµ­í•´ì–‘ìˆ˜ì‚°ê°œë°œì›(KMI) (2024.05 ~ 2024.07)**
- ë¶ê·¹í•­ë¡œì§€ì›ë‹¨
- ì§€ì •í•™ì  ì´ìŠˆê°€ í•­ë§Œ ë¬¼ë™ëŸ‰ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„
- ë°ì´í„° ìˆ˜ì§‘/ì „ì²˜ë¦¬/í†µê³„ ëª¨ë¸ë§

**ë¶€ì‚°ëŒ€í•™êµ ëŒ€í•™ì› (2022.09 ~ 2024.08)**
- í†µê³„í•™ê³¼ ì„ì‚¬ ì¡¸ì—… | GPA 4.19/4.5
- ìì—°ì–´ì²˜ë¦¬, ì´ë¯¸ì§€ ë¶„ë¥˜, ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬ ë“± AI/ML ì—°êµ¬
- ì„ì‚¬ ë…¼ë¬¸ ì‘ì„±

**ë¶€ì‚°ëŒ€í•™êµ (2017.03 ~ 2022.08)**
- í†µê³„í•™ê³¼ í•™ì‚¬ ì¡¸ì—… | GPA 3.67/4.5
- í†µê³„í•™ ì´ë¡  ë° ë°ì´í„° ë¶„ì„
- Python ê¸°ë°˜ ëª¨ë¸ë§ í•™ìŠµ

### ìê²©ì¦ ë° ì–´í•™

**ë¹…ë°ì´í„°ë¶„ì„ê¸°ì‚¬** (2023.12 ì·¨ë“)
- í•œêµ­ë°ì´í„°ì‚°ì—…ì§„í¥ì›ì¥ ë°œê¸‰

**TOEIC Speaking** (2024.09)
- Intermediate High
- ì˜ì–´ íšŒí™” ëŠ¥ë ¥ ê²€ì¦
"""

    system_prompt = f"""ë‹¹ì‹ ì€ ë°°ê²½ë“ ì§€ì›ìì˜ AI ë¹„ì„œì…ë‹ˆë‹¤.
ë©´ì ‘ê´€ì´ë‚˜ ì±„ìš© ë‹´ë‹¹ìê°€ ë°°ê²½ë“ ì§€ì›ìì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ë©´, ì•„ë˜ í¬íŠ¸í´ë¦¬ì˜¤ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

## ì‘ë‹µ ê·œì¹™
1. í•­ìƒ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
2. í¬íŠ¸í´ë¦¬ì˜¤ì— ëª…ì‹œëœ ë‚´ìš©ë§Œ ë‹µë³€í•˜ê³ , ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”
3. ê¸°ìˆ ì ì¸ ì§ˆë¬¸ì—ëŠ” êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ì„±ê³¼ë¥¼ í¬í•¨í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”
4. í”„ë¡œì íŠ¸ ê´€ë ¨ ì§ˆë¬¸ì—ëŠ” ì—­í• , ê¸°ì—¬ë„, ì‚¬ìš© ê¸°ìˆ , ì„±ê³¼ë¥¼ ëª…í™•íˆ ì„¤ëª…í•˜ì„¸ìš”
5. ì‘ë‹µì€ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤: {{"reply": "ë‹µë³€ ë‚´ìš©", "suggested_questions": ["ì¶”ì²œ ì§ˆë¬¸1", "ì¶”ì²œ ì§ˆë¬¸2"]}}

## ë°°ê²½ë“ ì§€ì›ì í¬íŠ¸í´ë¦¬ì˜¤
{portfolio_content}

## ì¶”ì²œ ì§ˆë¬¸ ì˜ˆì‹œ
- "KAMCO í”„ë¡œì íŠ¸ì—ì„œ êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ì—­í• ì„ í•˜ì…¨ë‚˜ìš”?"
- "RAG ì‹œìŠ¤í…œì˜ ë‹µë³€ ì •í™•ë„ 92%ëŠ” ì–´ë–»ê²Œ ë‹¬ì„±í•˜ì…¨ë‚˜ìš”?"
- "LangGraph ê¸°ë°˜ AI Agentì˜ í•µì‹¬ ê¸°ëŠ¥ì€ ë¬´ì—‡ì¸ê°€ìš”?"
- "ê°€ì¥ ìì‹ ìˆëŠ” ê¸°ìˆ  ìŠ¤íƒì€ ë¬´ì—‡ì¸ê°€ìš”?"
- "ìµœê·¼ ê´€ì‹¬ìˆëŠ” AI ê¸°ìˆ  ë¶„ì•¼ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
"""

    try:
        client = genai.Client(api_key=api_key)

        contents = []
        for turn in request.history:
            contents.append({"role": turn["role"], "parts": [{"text": turn["parts"]}]})
        contents.append({"role": "user", "parts": [{"text": request.message}]})

        response = client.models.generate_content(
            model='gemini-2.5-flash',
            contents=contents,
            config=types.GenerateContentConfig(
                system_instruction=system_prompt,
                temperature=0.7,
                response_mime_type="application/json",
                response_schema={"type": "object", "properties": {"reply": {"type": "string"}, "suggested_questions": {"type": "array", "items": {"type": "string"}}}}
            )
        )

        gemini_response = json.loads(response.text)
        return {
            "reply": gemini_response.get("reply", "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."),
            "suggested_questions": gemini_response.get("suggested_questions", [])
        }

    except Exception as e:
        print(f"[í¬íŠ¸í´ë¦¬ì˜¤] Gemini API ì˜¤ë¥˜: {e}", flush=True)
        return {"reply": "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", "suggested_questions": []}


# --- Product API Endpoints ---

def serialize_product(row: dict) -> dict:
    """Convert DB row to JSON-serializable dict with proper JSONB handling."""
    result = dict(row)
    # Convert datetime fields to ISO strings
    for key in ("created_at", "updated_at"):
        if key in result and result[key] is not None:
            result[key] = result[key].isoformat()
    # Ensure JSONB fields are dicts (asyncpg auto-decodes, but just in case)
    for key in ("name", "description", "category_name", "detail_info", "specs", "compatibility"):
        if key in result and isinstance(result[key], str):
            result[key] = json.loads(result[key])
    return result


@app.get("/api/health")
async def health_check():
    from db import pool
    db_url = os.environ.get("DATABASE_URL", "NOT SET")
    # ë¹„ë°€ë²ˆí˜¸ ìˆ¨ê¸°ê¸°
    if ":" in db_url and "@" in db_url:
        safe_url = db_url[:db_url.index("://") + 3] + "***@" + db_url[db_url.index("@") + 1:]
    else:
        safe_url = db_url
    return {
        "db_pool": "connected" if pool else "None",
        "db_url_set": db_url != "NOT SET",
        "db_url_preview": safe_url[:80]
    }


@app.get("/api/products")
async def api_get_products(category: str = None, search: str = None):
    products = await get_all_products(category=category, search=search)
    return [serialize_product(p) for p in products]


@app.get("/api/products/{product_id}")
async def api_get_product(product_id: int):
    product = await get_product_by_id(product_id)
    if not product:
        return {"error": "Product not found"}
    return serialize_product(product)


@app.post("/api/products")
async def api_create_product(product: ProductCreate):
    created = await create_product(product.model_dump())
    if not created:
        return {"error": "Failed to create product (DB not connected)"}
    return serialize_product(created)


@app.get("/api/site-settings")
async def get_site_settings():
    """ì‚¬ì´íŠ¸ ì„¤ì • ì¡°íšŒ (ê³µê°œ ì—”ë“œí¬ì¸íŠ¸ - í™ˆí˜ì´ì§€ìš©)"""
    from db import vector_pool
    if not vector_pool:
        return {}
    async with vector_pool.acquire() as conn:
        rows = await conn.fetch("SELECT key, value FROM site_settings")
    return {row["key"]: row["value"] for row in rows}


# ì‹¤í–‰ ë°©ë²• ì£¼ì„:
# í„°ë¯¸ë„ì—ì„œ: uvicorn app:app --reload


if __name__ == "__main__":
    import uvicorn
    from decouple import config

    # Railwayê°€ ì œê³µí•˜ëŠ” í¬íŠ¸ ë²ˆí˜¸ë¥¼ ê°€ì ¸ì˜´ (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 8000)
    port = int(os.environ.get("PORT", 8000))

    print(f"ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤! í¬íŠ¸: {port}")

    uvicorn.run("app:app", host="0.0.0.0", port=port, reload=False)
